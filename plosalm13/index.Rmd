---
title       : Programmatic access for Altmetrics
date        : 2013-10-10
author      : Scott Chamberlain (@recology_)
job         : rOpenSci / Simon Fraser University
framework   : io2012        # {io2012, html5slides, shower, dzslides, ...}
highlighter : highlight.js  # {highlight.js, prettify, highlight}
hitheme     : solarized_light      # 
widgets     : [nvd3]            # {mathjax, quiz, bootstrap}
mode        : selfcontained # {standalone, draft}
assets      :
  css: "http://netdna.bootstrapcdn.com/font-awesome/3.2.1/css/font-awesome.css"
---

<!-- 
SHOOTING FOR 15 MIN (15-20 IS GOOD, BUT DO NO MORE THAN 15 MIN.) 
-->
<br><br>
<center><img src="assets/img/ropensci_main.png"></center>

<br>
<center>
### Find this talk here [http://bit.ly/roalm](http://bit.ly/roalm)

### Made with [Slidify](http://slidify.org/); the code [here](https://github.com/SChamberlain/posterstalks/blob/gh-pages/plosalm13/index.Rmd)

### Press "o" to bring up all slides - "w" to change aspect - "g" to go to page
</center>

---

<br><br><br>

<font size="14"><center> Programmatic access to altmetrics <br><br>
Open altmetrics data</center></font>

---

## Programmatic access

<center>![](assets/img/code.png)</center>

<!-- used by the provider themselves, publishers, in a web browser, and from the command line -->

---

## Programmatic access to altmetrics

Computers are simply better at repetitive tasks

* Makes repetitive tasks take far less time
* Facilitates tool creation by developers
* Allows research questions to be addressed more quickly
* Facilitates reproducibility

--- 

<br><br><br>
<font size="14"><center>What is needed for easy programmatic access?</center></font>

--- 

## Modern API technology

[REST API](http://en.wikipedia.org/wiki/REST_API)

The modern way to serve data to consumers<br>
Makes data consumption easy from any programming language

* Base URI, e.g. http://foo.com
* Media type, e.g., json, xml
* HTTP verbs, like GET, POST, PUT, PATCH, HEAD, etc...

---

## Proper HTTP status codes

* 1xx - informational
* 2xx - success
* 3xx - redirection
* 4xx - client error
* 5xx - server error

---

<br>
<center>![](assets/img/shutdown.png)</center>

<!-- Gives 200 status code, instead of e.g., 503 "Service Unavailable" -->

--- 

## Good docs (for developers)

<br>
<center>![](assets/img/book.png)</center>

--- 

## Authentication
<br>
OAuth makes sense for web workflows, but not so much for programmatic workflows.

Having both options is nice.

---

## A spec for REST?

RAML - [http://raml.org/](http://raml.org/)

Programatically create new clients

```coffee
#%RAML 0.8
–––
title: World Music API
baseUri: http://example.api.com/{version}
version: v1
 /songs:
   get:
   post: 
  ...
```

Good place to include altmetrics standards...

---

## Deploying APIs is probably hard

<br>
<center>![](assets/img/code-fork.png)</center>

---

<br><br><br>
<font size="14"><center>Consuming altmetrics programmatically</center></font>

---

## We need altmetrics research

<center>![](assets/img/beaker.png)</center>

<!-- 
if we are to avoid mistakes of JIF, we need research on altmetrics
-->

---

## Programmatic access to altmetrics data key for reproducibility
<center>![](assets/img/spinner.png)</center>

---

## Having a look at the literature...

* [Do Altmetrics Work? Twitter and Ten Other...](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0064841) - via Altmetric.com
* [Tweeting biomedicine: an analysis of tweets...](http://arxiv.org/pdf/1308.1838v1.pdf) - via Altmetric.com
* [The Spread of Scientific Information...](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0019917) - via PLOS ALM
* [Can Tweets Predict Citations? ...](http://www.jmir.org/2011/4/e123/) - via Twitter Search API
* [Altmetrics in the Wild...](http://arxiv.org/html/1203.4745v1) - via PLOS ALM, various APIs, WebofSci citations
* [Social Media Release Increases Dissemination...](http://www.ploscollections.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0068914) - via manual collection
* [Identifying Audiences of E-Infrastructures...](http://www.ploscollections.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0050943) - via Google Analytics
* [How the Scientific Community Reacts to...](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047523) - via Twitter Search API, Google Scholar citations

---

<br><br><br>
<font size="14"><center>Most popular programming language?</center></font>

---

<br>
<center>![](assets/img/excel.png)</center>

Obviously

---

<br>
<div class="row" align="center">
  <img src="assets/img/ropensci_main.png">
  <img src="assets/img/swc.png">
</div>

---

## Many libraries available, but more needed

| Data source   | Libraries            | rOpenSci Contributions in R
| ------------- | -------------        | ---------
| PLOS ALM      | R                    | [alm][alm] ** Copernicus, etc.
| ImpactStory   | R, Javascript        | [rImpactStory][ris]
| Altmetric     | R, Python, Ruby, iOS | [rAltmetric][ralt]

[alm]: http://cran.r-project.org/web/packages/alm/index.html
[ris]: http://cran.r-project.org/web/packages/rImpactStory/index.html
[ralt]: http://cran.r-project.org/web/packages/rAltmetric/index.html

---

## Interacting with REST APIs in R


```r
out <- GET("http://alm.plos.org/api/v3/articles?doi=10.1371/journal.pmed.1001361&key=<key>")
stop_for_status(out)
content(out)
```

```r
{
  doi: "10.1371/journal.pmed.1001361",
  title: "Personalized Prediction of Lifetime Benefits with Statin Therapy for Asymptomatic Individuals: A Modeling Study",
  url: "http://www.plosmedicine.org/article/info%3Adoi%2F10.1371%2Fjournal.pmed.1001361",
  mendeley: "437b07d9-bc40-4c57-b60e-1f60fefe2300",
  pmid: "23300388",
  pmcid: "3531501",
  publication_date: "2012-12-27T08:00:00Z",
  update_date: "2013-10-07T11:06:58Z",
  views: 9329,
  shares: 62,
  bookmarks: 5,
  citations: 1
}
```
<!-- very easy to get altmetrics data --> 

---

## Data via alm interface to PLOS ALM

```{r metawithdata, eval=FALSE}
alm(doi="10.1371/journal.pone.0029797")
```

```coffee
An object of class "almtot"
Slot "meta":
$doi
[1] "10.1371/journal.pone.0029797"
...<more metadata>

Slot "summary":
  views shares bookmarks citations
1 29229    237        51         7

Slot "data":
                .id  pdf  html shares groups comments likes citations total
1         bloglines   NA    NA     NA     NA       NA    NA         0     0
2         citeulike   NA    NA      1     NA       NA    NA        NA     1
3          connotea   NA    NA     NA     NA       NA    NA         0     0
4          crossref   NA    NA     NA     NA       NA    NA         7     7
5            nature   NA    NA     NA     NA       NA    NA         4     4
...
```
<!-- can provide metadata along with data tables for easy manipulation
--> 
---

## Metadata

```{r meta, comment=NA, warning=FALSE, message=FALSE}
almmeta("mendeley")
```

<!-- a thing I'm working on is detailed metadata a user can 
call up 
--> 

---

<style type="text/css">
  table {
    border: none;
    width: 100%;
    border-collapse: collapse;
    font-size: 24px;
    line-height: 12px;
    font-family: 'Trebuchet MS';
    font-weight: bolder;
    color: rgb(102, 102, 102);
  }

  table td, table th {
    font-size: 20px;
    padding: 1em 0.5em;
  } 
</style>

## Combining metrics across aggregators
<br>

| Data source | PLoS | ImpactStory | Altmetric |
| ----------- | ---- | ----------- | --------- |
| WebOfScience | webofscience | -- | -- |
| Dryad | -- | dryad:total_downloads | -- |
| Figshare | figshare | figshare:views shares downloads | -- | 
| Github | -- | github:forks stars | -- |
| Google+ | -- | -- | cited by gplus count |
| Mendeley readers | mendeley shares | mendeley readers | mendeley readers |
| Twitter | twitter | topsy:tweets | cited by tweeters count |

---

## Proposed R library

metaAlm - (*doesn't actually exist*) 
<br><br>
Combine altmetrics data across providers (ImpactStory, Altmetric, etc.)
<br>
and across data sources (Twitter, Facebook, etc.)

---

## Combining metrics

### Get data from three different providers

```coffee
plos_data <- alm(<doi>)
impactstory_data <- metrics(<doi>)
altmetric_data <- altmetric_data(altmetrics(<doi>))
```

### Easily combine data with a single function, and highlight inconsistencies

```{r echo=FALSE}
alt_combine <- function(...){
  message("Warning: Inconsistency in facebookLikes, check metadata")
  data.frame(dataSource= c("twitter","facebookLikes","facebookLikes","scopusCitations"), 
             fromProvider = c("PLOSALM", "ImpactStory", "Altmetric", "Altmetric"), 
             values = c(100, 50, 40, 150))
}
```

```{r comment=NA}
alt_combine(plos_data, impactstory_data, altmetric_data)
```

--- 

## Example in R

Load libraries, get 200 DOIs, get ALM data, plot

```{r plot, message=FALSE, warning=FALSE, comment=NA, cache=TRUE, tidy=FALSE, fig.height=5.5, fig.width=10, fig.align='center'}
library(rplos); library(alm); library(plyr)
dois <- searchplos(terms='*:*', fields="id", limit=200)
alm <- ldply( alm(doi=do.call(c,dois$id), total_details=TRUE) )
plot_density(alm, c("counter_pdf","mendeley_shares","pmc_pdf","pmc_total"), c("#83DFB4","#EFA5A5","#CFD470","#B2C9E4"), plot_type="h")
```

---

```{r inter, message=FALSE, warning=FALSE, comment=NA, cache=TRUE, tidy=FALSE}
library(rplos); library(alm); library(rCharts)
dois <- c('10.1371/journal.pone.0001543','10.1371/journal.pone.0040117','10.1371/journal.pone.0029797','10.1371/journal.pone.0039395')
dat <- signposts(doi=dois)
```

```{r inter2, message=FALSE, warning=FALSE, comment=NA, cache=TRUE, results='asis'}
plot_signposts(input=dat, type="multiBarChart", height=400)
```

---
<br>
<center>![](assets/img/unlock.png)</center>

---

<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>

<br><br><br>
<blockquote class="twitter-tweet"><p>“I’d argue that <a href="https://twitter.com/search?q=%23opendata&amp;src=hash">#opendata</a> today is exactly where open source was some 2 decades ago”-<a href="https://twitter.com/BenBalter">@BenBalter</a> <a href="http://t.co/VJ6QiLybUU">http://t.co/VJ6QiLybUU</a> <a href="https://twitter.com/search?q=%23oss&amp;src=hash">#oss</a></p>&mdash; Alex Howard (@digiphile) <a href="https://twitter.com/digiphile/statuses/388089575346028544">October 9, 2013</a></blockquote>

---

## Why is openness a good thing?

Altmetrics needs checks on

* Consistency (tweets from source A and B should be =)
* Correlation (is metric A strongly corr. with B?)
* Interpretation (open source the interpretation)
* Gaming (security through obscurity doesn't work)

<!-- 
This can be done better when data is open and easily available.
-->

---

## Why is openness a good thing?

Altmetrics needs checks on

* Consistency (tweets from source A and B should be =)
* Correlation (is metric A strongly corr. with B?)
* Interpretation (open source the interpretation)
* Gaming (security through obscurity doesn't work)

<br><br>
**Open data makes all this easier**

---

## Additional value from openness

* Knowledge from research findings
  * Doesn't require open data I suppose :(, but helps facilitate research
  * e.g., think how hard text-mining is - we don't want that in altmetrics
* Open products
  * [ReaderMeter](http://readermeter.org/)
  * [ScienceCard](http://sciencecard.org/)
* For-profit products
* Who knows? Making data open allows many experiments, some of which will stick

---

## An open use case

*Are individual altmetrics consistent among data providers?*

```{r isqfig3, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.width=11, fig.height=6, fig.align='center'}
library(ggplot2)
library(reshape2)
library(reshape)
library(lubridate)

dat <- read.csv("~/github/sac/isqaltms/alldatout_3.csv")[-1,]
dat2 <- read.csv("~/github/sac/isqaltms/plumout.csv")[-1,]
dat2 <- dat2[dat2$doi %in% dat$doi, ]
dat2 <- data.frame(provider='plum', dat2)

alldat <- rbind.fill(dat, dat2)
alldat <- sort_df(alldat, "doi")

dat_split <- split(alldat, f=alldat$doi)
dat_split <- dat_split[!sapply(dat_split, nrow)==0]
dat_split <- compact(lapply(dat_split, function(x) {if(x$citeulike[2]==999){NULL} else(x) }))
dat_split_df <- ldply(dat_split)[,-1]

datediff <- function(x){
  datesorted <- sort(x)
  round(as.numeric(difftime(datesorted[3], datesorted[1])),0)
}

calcdiff <- function(x){max(na.omit(x))-min(na.omit(x))}

dat_split_df2 <- dat_split_df[!dat_split_df$provider %in% "plum",] # remove plum as no updated dates given
dat_split_df_1 <- ddply(dat_split_df2, .(doi), numcolwise(calcdiff))
dat_split_df_2 <- ddply(dat_split_df2, .(doi), summarise, datediff = datediff(date_modified))
dat_split_df_melt <- melt(dat_split_df_1)
dat_split_df_ <- merge(dat_split_df_melt, dat_split_df_2, by="doi")
dat_split_df_melt <- dat_split_df_[! dat_split_df_$variable %in% "connotea", ] # connotea isn't shared among the providers

ggplot(dat_split_df_melt, aes(x=datediff, y=log10(value+1), colour=variable)) +
  theme_bw(base_size=22) +
  geom_point(size=3, alpha=0.6) +
  scale_colour_brewer("Source", type="qual", palette=3) +
  theme(panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position = c(0.65, 0.9), 
        panel.border = element_rect(size=1),
        legend.key=element_blank(), 
        panel.background=element_rect(colour="white")) +
  guides(col=guide_legend(nrow=2, override.aes=list(size=4))) +
  labs(x="\nDate difference (no. of days)", y="Value of difference between max and min\n")
```

<font size="6"><a href="http://www.niso.org/publications/isq/2013/v25no2/chamberlain">10.3789/isqv25no2.2013.02</a></font>

---

<br><br><br>

<font size="14"><center> Programmatic access <br><br>
Open altmetrics data</center></font>

---

<br><br><br>
<center><font size="14">Programmatic access</font></center><br>
<center><img src="assets/img/heart.png"></center><br>
<center><font size="14">open data</font></center>

---

<br><br><br>

<font size="14"><center> Programmatic access to Open altmetrics data</center></font>